{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\n",
    "    \"12f4b1fc58f4a13b0e5bc8d854c0b9cf9abd7422082631bfec2787ebb7ffb928\",\n",
    "    \"33c62168d74030abe560c3ad9d3281a040db4ff5eb2006e423afb99e129c6ee9\",\n",
    "    \"e3207d8e111207a6411ab78f0523b4b0f7a20689410cfdfa9fb7c1216ee84841\",\n",
    "    \"c531d4a648804161bb266dc5e338e80ed8287f50ae1443cfa3d065b348970163\",\n",
    "    \"e0bcfea24c34654ffc13a9bd43681b6e1b89a608fcc5b014a27e3572621fc5d3\",\n",
    "    \"a4cd330134a6d4973a5cbbd2ba5e77ddf52f31a920a853ee4ddd80ecf0c6edca\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(dir_path, day, targets=None):\n",
    "    invocation_fpattern = \"invocations_per_function_md.anon.d%02d.csv\"\n",
    "    df = pd.read_csv(dir_path.joinpath(invocation_fpattern % day))\n",
    "    if targets is None:\n",
    "        return df\n",
    "    else:\n",
    "        return df[df.HashFunction.isin(targets)].sort_values(\"HashFunction\").reset_index(drop=True)\n",
    "\n",
    "target_dir = Path(\"/srv/local/bj2/azure_2019\")\n",
    "\n",
    "dfs = {}\n",
    "for i in range(8, 13):\n",
    "    dfs[i] = load_df(target_dir, i, targets=keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_df(df, day):\n",
    "    keys = []\n",
    "    counts = []\n",
    "    for _, s in df.iterrows():\n",
    "        keys.append(s[\"HashFunction\"])\n",
    "        counts.append(np.array([s[str(i)] for i in np.arange(1, 1441)], dtype=np.int32))\n",
    "\n",
    "    counts = [pd.Series(c, dtype=np.int32) for c in counts]\n",
    "    return pd.DataFrame({\"hash_func\": keys, \"day\": np.repeat(day, len(keys)), \"counts\": counts})\n",
    "\n",
    "parsed_dfs = {day: parse_df(df, day) for day, df in dfs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale1d(count, target=50, limit_only=False):\n",
    "    print(f\"len={len(count)}\")\n",
    "    if limit_only:\n",
    "        if np.max(count) > target:\n",
    "            # normalize and remap to [0, target]\n",
    "            new_count = count / np.max(count) * target\n",
    "            return np.round(new_count).astype(np.int32)\n",
    "        else:\n",
    "            return count\n",
    "    else:\n",
    "        new_count = count / np.max(count) * target\n",
    "        return np.round(new_count).astype(np.int32)\n",
    "\n",
    "def scale2d(counts2d, target=50):\n",
    "    # normalize counts when their max qps > target\n",
    "    new_counts = []\n",
    "    for counts in counts2d:\n",
    "        new_counts.append(scale1d(counts, target))\n",
    "    return np.stack(new_counts)\n",
    "\n",
    "def scale_df(df, target=50):\n",
    "    # normalize counts when their max qps > target\n",
    "    df = df.copy()\n",
    "    scaled_series = []\n",
    "    for i in df.index:\n",
    "        scaled_series.append(pd.Series(scale1d(df.loc[i, \"counts\"], target)))\n",
    "    df.counts = scaled_series\n",
    "    # for series in df.counts:\n",
    "    #     series.update(pd.Series(scale1d(series, target)))\n",
    "    # for counts in df.counts:\n",
    "    #     counts[:] = scale1d(counts, target)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale1d_avg(count, target):\n",
    "    avg = np.mean(count)\n",
    "    factor = target / avg\n",
    "    return count * factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "\n",
    "def scale_dfs(dfs, scale_fn):\n",
    "    scaled_counts_list = []\n",
    "    for i, key in enumerate(sorted(keys)):\n",
    "        counts = []\n",
    "        for day, df in dfs.items():\n",
    "            target = df.iloc[i]\n",
    "            assert target.hash_func == key\n",
    "            counts.append(target.counts)\n",
    "        scaled_counts = [\n",
    "            pd.Series(s) for s\n",
    "            in np.split(scale_fn(pd.concat(counts).to_numpy()), len(dfs))]\n",
    "        scaled_counts_list.append(scaled_counts)\n",
    "\n",
    "    scaled_dfs = {}\n",
    "    for (day, df), scaled_counts in zip(dfs.items(), zip(*scaled_counts_list)):\n",
    "        scaled_df = df.copy()\n",
    "        scaled_df.counts = scaled_counts\n",
    "        scaled_dfs[day] = scaled_df\n",
    "    return scaled_dfs\n",
    "\n",
    "scale_fn = functools.partial(scale1d, target=50, limit_only=True)\n",
    "# scale_fn = functools.partial(scale1d_avg, target=210)\n",
    "scaled_dfs = scale_dfs(parsed_dfs, scale_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_count_dict(dfs):\n",
    "    counts_dict = defaultdict(list)\n",
    "\n",
    "    for day, df in sorted(dfs.items()):\n",
    "        for _, row in df.iterrows():\n",
    "            counts_dict[row.hash_func].append(row.counts)\n",
    "\n",
    "    return {\n",
    "        hash_func: pd.concat(counts).reset_index(drop=True) for hash_func, counts in counts_dict.items()\n",
    "    }\n",
    "\n",
    "unscaled_count_dict = generate_count_dict(parsed_dfs)\n",
    "scaled_count_dict = generate_count_dict(scaled_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, count in unscaled_count_dict.items():\n",
    "    print(k[:5], np.mean(count))\n",
    "\n",
    "print()\n",
    "for k, count in scaled_count_dict.items():\n",
    "    print(k[:5], np.mean(count))\n",
    "\n",
    "print(np.sum([np.mean(count) for k, count in scaled_count_dict.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(counts_dict):\n",
    "    for hash_func, counts in counts_dict.items():\n",
    "        fig, ax = plt.subplots(figsize=(18, 4))\n",
    "        ax.plot(counts, label=hash_func[:10])\n",
    "        ax.set_xlim(0, len(counts))\n",
    "        for i in range(1440, len(counts), 1440):\n",
    "            ax.axvline(i, color=\"red\")\n",
    "        ax.legend()\n",
    "\n",
    "plot(unscaled_count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(scaled_count_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('k8s-ray')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "791032b3b1abebe9cd98cfd1a64eed260e0c42a95acc06a92e25bdb2ff748fab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
